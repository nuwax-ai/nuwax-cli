//! # ä¸‹è½½æ¨¡å—
//!
//! æä¾›ç»Ÿä¸€çš„æ–‡ä»¶ä¸‹è½½æ¥å£ï¼Œæ”¯æŒï¼š
//! - æ™®é€š HTTP ä¸‹è½½
//! - é˜¿é‡Œäº‘ OSS å…¬ç½‘æ–‡ä»¶ä¸‹è½½ï¼ˆæ‰©å±•è¶…æ—¶ï¼‰
//! - **æ–­ç‚¹ç»­ä¼ ä¸‹è½½** â­
//! - è¿›åº¦å›è°ƒå’Œç›‘æ§
//! - æ–‡ä»¶å®Œæ•´æ€§éªŒè¯
//! - æ™ºèƒ½ç¼“å­˜å’Œæ–­ç‚¹ç»­ä¼ 
//!
//! ## ä¸»è¦ç‰¹æ€§
//!
//! ### æ™ºèƒ½ä¸‹è½½ç­–ç•¥
//! - è‡ªåŠ¨æ£€æµ‹ä¸‹è½½æ–¹å¼ï¼ˆHTTP/æ‰©å±•è¶…æ—¶HTTPï¼‰
//! - æ”¯æŒé˜¿é‡Œäº‘ OSS å¤§æ–‡ä»¶ä¸‹è½½ï¼ˆå…¬ç½‘è®¿é—®ï¼‰
//! - æ‰©å±•è¶…æ—¶æ—¶é—´é¿å…å¤§æ–‡ä»¶ä¸‹è½½å¤±è´¥
//! - **æ™ºèƒ½æ–­ç‚¹ç»­ä¼ ** - è‡ªåŠ¨æ£€æµ‹å·²ä¸‹è½½éƒ¨åˆ†ï¼Œä»ä¸­æ–­ç‚¹ç»§ç»­
//!
//! ### è¿›åº¦ç›‘æ§
//! - å®æ—¶ä¸‹è½½è¿›åº¦å›è°ƒ
//! - ä¸‹è½½é€Ÿåº¦è®¡ç®—
//! - å‰©ä½™æ—¶é—´ä¼°ç®—
//!
//! ### æ–‡ä»¶å®Œæ•´æ€§
//! - SHA-256 å“ˆå¸ŒéªŒè¯
//! - æŸåæ–‡ä»¶è‡ªåŠ¨é‡è¯•
//! - å®Œæ•´æ€§æ ¡éªŒç¼“å­˜
//!
//! ### æ–­ç‚¹ç»­ä¼ 
//! - HTTP Range è¯·æ±‚æ”¯æŒ
//! - è‡ªåŠ¨æ£€æµ‹å·²ä¸‹è½½éƒ¨åˆ†
//! - æ™ºèƒ½æ–‡ä»¶å®Œæ•´æ€§éªŒè¯
//! - æ”¯æŒå¤§æ–‡ä»¶ä¸‹è½½æ¢å¤

use crate::error::DuckError;
use anyhow::Result;
use chrono;
use futures::stream::StreamExt;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use std::path::Path;
use std::time::Duration;
use tokio::fs::{File, OpenOptions};
use tokio::io::{AsyncReadExt, AsyncWriteExt};
use tracing::{info, warn};

/// ä¸‹è½½è¿›åº¦çŠ¶æ€æšä¸¾
#[derive(Debug, Clone)]
pub enum DownloadStatus {
    Starting,
    Downloading,
    Resuming, // æ–­ç‚¹ç»­ä¼ çŠ¶æ€ â­
    Paused,
    Completed,
    Failed(String),
}

/// ä¸‹è½½è¿›åº¦ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct DownloadProgress {
    pub task_id: String,
    pub file_name: String,
    pub downloaded_bytes: u64,
    pub total_bytes: u64,
    pub download_speed: f64, // bytes/sec
    pub eta_seconds: u64,
    pub percentage: f64,
    pub status: DownloadStatus,
}

/// ä¸‹è½½ä»»åŠ¡å…ƒæ•°æ® â­
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DownloadMetadata {
    pub url: String,
    pub expected_size: u64,
    pub expected_hash: Option<String>,
    pub downloaded_bytes: u64,
    pub start_time: String,
    pub last_update: String,
    pub version: String, // ä¸‹è½½ä»»åŠ¡ç‰ˆæœ¬ï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„ä¸‹è½½
}

impl DownloadMetadata {
    /// åˆ›å»ºæ–°çš„ä¸‹è½½å…ƒæ•°æ®
    pub fn new(
        url: String,
        expected_size: u64,
        expected_hash: Option<String>,
        version: String,
    ) -> Self {
        let now = chrono::Utc::now().to_rfc3339();
        Self {
            url,
            expected_size,
            expected_hash,
            downloaded_bytes: 0,
            start_time: now.clone(),
            last_update: now,
            version,
        }
    }

    /// æ›´æ–°ä¸‹è½½è¿›åº¦
    pub fn update_progress(&mut self, downloaded_bytes: u64) {
        self.downloaded_bytes = downloaded_bytes;
        self.last_update = chrono::Utc::now().to_rfc3339();
    }

    /// æ£€æŸ¥æ˜¯å¦ä¸ºç›¸åŒçš„ä¸‹è½½ä»»åŠ¡
    pub fn is_same_task(&self, url: &str, expected_size: u64, version: &str) -> bool {
        self.url == url && self.expected_size == expected_size && self.version == version
    }
}

/// ä¸‹è½½å™¨ç±»å‹
#[derive(Debug, Clone)]
pub enum DownloaderType {
    Http,
    HttpExtendedTimeout,
}

/// æ–‡ä»¶ä¸‹è½½å™¨é…ç½®
#[derive(Debug, Clone)]
pub struct DownloaderConfig {
    pub timeout_seconds: u64,
    pub chunk_size: usize,
    pub retry_count: u32,
    pub enable_progress_logging: bool,
    pub enable_resume: bool,            // å¯ç”¨æ–­ç‚¹ç»­ä¼  â­
    pub resume_threshold: u64,          // æ–­ç‚¹ç»­ä¼ é˜ˆå€¼ï¼ˆå­—èŠ‚ï¼‰ï¼Œå°äºæ­¤å€¼çš„æ–‡ä»¶é‡æ–°ä¸‹è½½ â­
    pub progress_interval_seconds: u64, // è¿›åº¦æ˜¾ç¤ºæ—¶é—´é—´éš”ï¼ˆç§’ï¼‰â­
    pub progress_bytes_interval: u64,   // è¿›åº¦æ˜¾ç¤ºå­—èŠ‚é—´éš” â­
    pub enable_metadata: bool,          // å¯ç”¨å…ƒæ•°æ®ç®¡ç† â­
}

impl Default for DownloaderConfig {
    fn default() -> Self {
        Self {
            timeout_seconds: 60 * 60, // 60åˆ†é’Ÿ
            chunk_size: 8192,         // 8KB
            retry_count: 3,
            enable_progress_logging: true,
            enable_resume: true,                        // é»˜è®¤å¯ç”¨æ–­ç‚¹ç»­ä¼  â­
            resume_threshold: 1024 * 1024,              // 1MBï¼Œå°äº1MBçš„æ–‡ä»¶é‡æ–°ä¸‹è½½ â­
            progress_interval_seconds: 10,              // æ¯10ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ â­
            progress_bytes_interval: 100 * 1024 * 1024, // æ¯100MBæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦ â­
            enable_metadata: true,                      // é»˜è®¤å¯ç”¨å…ƒæ•°æ®ç®¡ç† â­
        }
    }
}

/// æ–‡ä»¶ä¸‹è½½å™¨
pub struct FileDownloader {
    config: DownloaderConfig,
    client: Client,
    custom_client: Option<Client>, // æ”¯æŒè‡ªå®šä¹‰HTTPå®¢æˆ·ç«¯ï¼ˆç”¨äºè®¤è¯ï¼‰ â­
}

impl FileDownloader {
    /// åˆ›å»ºæ–°çš„æ–‡ä»¶ä¸‹è½½å™¨
    pub fn new(config: DownloaderConfig) -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout_seconds))
            .user_agent(crate::constants::api::http::USER_AGENT) // ğŸ†• æ·»åŠ User-Agent â­
            .build()
            .expect("Failed to create HTTP client");

        Self {
            config,
            client,
            custom_client: None,
        }
    }

    /// åˆ›å»ºæ”¯æŒè‡ªå®šä¹‰HTTPå®¢æˆ·ç«¯çš„ä¸‹è½½å™¨ï¼ˆç”¨äºè®¤è¯åœºæ™¯ï¼‰â­
    pub fn new_with_custom_client(config: DownloaderConfig, custom_client: Client) -> Self {
        let fallback_client = Client::builder()
            .timeout(Duration::from_secs(config.timeout_seconds))
            .user_agent(crate::constants::api::http::USER_AGENT) // ğŸ†• æ·»åŠ User-Agent â­
            .build()
            .expect("Failed to create fallback HTTP client");

        Self {
            config,
            client: fallback_client,
            custom_client: Some(custom_client),
        }
    }

    /// è·å–è¦ä½¿ç”¨çš„HTTPå®¢æˆ·ç«¯ï¼ˆä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰å®¢æˆ·ç«¯ï¼‰â­
    fn get_http_client(&self) -> &Client {
        self.custom_client.as_ref().unwrap_or(&self.client)
    }

    /// åˆ›å»ºé»˜è®¤é…ç½®çš„ä¸‹è½½å™¨
    pub fn default() -> Self {
        Self::new(DownloaderConfig::default())
    }

    /// æ£€æŸ¥ URL æ˜¯å¦ä¸ºé˜¿é‡Œäº‘ OSS é“¾æ¥
    pub fn is_aliyun_oss_url(&self, url: &str) -> bool {
        url.starts_with("https://") && url.contains("aliyuncs.com") && url.contains("oss-")
    }

    /// æ£€æŸ¥ URL æ˜¯å¦ä¸ºå¯¹è±¡å­˜å‚¨æˆ–CDNæœåŠ¡ â­
    pub fn is_object_storage_or_cdn_url(&self, url: &str) -> bool {
        let url_lower = url.to_lowercase();

        // é˜¿é‡Œäº‘OSS
        if url_lower.contains("aliyuncs.com") && url_lower.contains("oss-") {
            return true;
        }

        // è…¾è®¯äº‘COS
        if url_lower.contains("myqcloud.com") && url_lower.contains("cos.") {
            return true;
        }

        // åä¸ºäº‘OBS
        if url_lower.contains("myhuaweicloud.com") && url_lower.contains("obs.") {
            return true;
        }

        // AWS S3
        if url_lower.contains("amazonaws.com")
            && (url_lower.contains("s3.") || url_lower.contains(".s3-"))
        {
            return true;
        }

        // ä¸ƒç‰›äº‘
        if url_lower.contains("qiniudn.com")
            || url_lower.contains("clouddn.com")
            || url_lower.contains("qnssl.com")
        {
            return true;
        }

        // åˆæ‹äº‘
        if url_lower.contains("upaiyun.com") || url_lower.contains("upyun.com") {
            return true;
        }

        // ç™¾åº¦äº‘BOS
        if url_lower.contains("bcebos.com") || url_lower.contains("baidubce.com") {
            return true;
        }

        // äº¬ä¸œäº‘OSS
        if url_lower.contains("jdcloud.com") && url_lower.contains("oss.") {
            return true;
        }

        // å¸¸è§CDNæœåŠ¡
        if url_lower.contains("cloudfront.net") ||  // AWS CloudFront
           url_lower.contains("fastly.com") ||      // Fastly
           url_lower.contains("jsdelivr.net") ||    // jsDelivr
           url_lower.contains("unpkg.com") ||       // unpkg
           url_lower.contains("cdnjs.com") ||       // cdnjs
           url_lower.contains("bootcdn.cn") ||      // BootCDN
           url_lower.contains("staticfile.org")
        {
            // é™æ€æ–‡ä»¶CDN
            return true;
        }

        false
    }

    /// åˆ¤æ–­ä¸‹è½½å™¨ç±»å‹
    pub fn get_downloader_type(&self, url: &str) -> DownloaderType {
        if self.is_object_storage_or_cdn_url(url) {
            // æ‰€æœ‰å¯¹è±¡å­˜å‚¨å’ŒCDN URL éƒ½ä½¿ç”¨æ‰©å±•è¶…æ—¶ HTTP ä¸‹è½½ï¼ˆå…¬ç½‘è®¿é—®ï¼‰
            DownloaderType::HttpExtendedTimeout
        } else {
            DownloaderType::Http
        }
    }

    /// æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ”¯æŒRangeè¯·æ±‚ â­
    async fn check_range_support(&self, url: &str) -> Result<(bool, u64)> {
        info!("ğŸ” å¼€å§‹æ£€æŸ¥Rangeæ”¯æŒ: {}", url);

        let response = self
            .get_http_client()
            .head(url)
            .send()
            .await
            .map_err(|e| DuckError::custom(format!("æ£€æŸ¥Rangeæ”¯æŒå¤±è´¥: {e}")))?;

        info!("ğŸ“‹ HTTPå“åº”çŠ¶æ€: {}", response.status());

        if !response.status().is_success() {
            return Err(anyhow::anyhow!(
                "æœåŠ¡å™¨å“åº”é”™è¯¯: HTTP {}",
                response.status()
            ));
        }

        // ğŸ†• è¯¦ç»†è°ƒè¯•ä¿¡æ¯ â­
        info!("ğŸ“‹ å“åº”å¤´éƒ¨è¯¦æƒ…:");
        for (name, value) in response.headers().iter() {
            if let Ok(value_str) = value.to_str() {
                info!("   {}: {}", name, value_str);
            } else {
                info!("   {}: <non-UTF8 value>", name);
            }
        }

        let total_size = response.content_length().unwrap_or(0);
        info!("ğŸ“¦ Content-Lengthè§£æç»“æœ: {} bytes", total_size);

        // ğŸ†• ä¿®å¤content_lengthè§£æé—®é¢˜ â­
        let total_size = if total_size == 0 {
            // å¦‚æœreqwestè§£æå¤±è´¥ï¼Œæ‰‹åŠ¨ä»å“åº”å¤´éƒ¨è§£æ
            if let Some(content_length_header) = response.headers().get("content-length") {
                if let Ok(content_length_str) = content_length_header.to_str() {
                    if let Ok(parsed_size) = content_length_str.parse::<u64>() {
                        info!("ğŸ“¦ æ‰‹åŠ¨è§£æContent-LengthæˆåŠŸ: {} bytes", parsed_size);
                        parsed_size
                    } else {
                        warn!("âš ï¸ Content-Lengthè§£æå¤±è´¥: {}", content_length_str);
                        0
                    }
                } else {
                    warn!("âš ï¸ Content-Lengthå¤´éƒ¨ä¸æ˜¯æœ‰æ•ˆçš„UTF-8å­—ç¬¦ä¸²");
                    0
                }
            } else {
                warn!("âš ï¸ å“åº”ä¸­æ²¡æœ‰Content-Lengthå¤´éƒ¨");
                0
            }
        } else {
            total_size
        };

        // åŸå§‹çš„Rangeæ”¯æŒæ£€æµ‹
        let explicit_range_support = response
            .headers()
            .get("accept-ranges")
            .and_then(|v| v.to_str().ok())
            .map(|v| v.contains("bytes"))
            .unwrap_or(false);

        // ğŸ†• å¯¹å¯¹è±¡å­˜å‚¨å’ŒCDNæœåŠ¡å™¨é‡‡ç”¨æ›´å®½æ¾çš„æ£€æµ‹ç­–ç•¥ â­
        let is_object_storage_or_cdn = self.is_object_storage_or_cdn_url(url);
        let supports_range = if is_object_storage_or_cdn {
            // å¯¹è±¡å­˜å‚¨å’ŒCDNæœåŠ¡å™¨é€šå¸¸æ”¯æŒRangeè¯·æ±‚ï¼Œå³ä½¿ä¸æ˜ç¡®è¿”å›Accept-Rangeså¤´éƒ¨
            info!("ğŸ” æ£€æµ‹åˆ°å¯¹è±¡å­˜å‚¨/CDNæœåŠ¡å™¨ï¼Œå‡è®¾æ”¯æŒRangeè¯·æ±‚ï¼ˆå¼ºåˆ¶å¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼‰");
            true
        } else {
            explicit_range_support
        };

        info!("ğŸ“‹ Rangeæ”¯æŒæ£€æµ‹ç»“æœ:");
        info!(
            "   æœåŠ¡å™¨ç±»å‹: {}",
            if is_object_storage_or_cdn {
                "å¯¹è±¡å­˜å‚¨/CDN"
            } else {
                "æ™®é€šHTTP"
            }
        );
        info!("   æ˜¾å¼Rangeæ”¯æŒ: {}", explicit_range_support);
        info!("   æœ€ç»ˆåˆ¤å®š: {}", supports_range);
        if let Some(accept_ranges) = response.headers().get("accept-ranges") {
            info!("   Accept-Rangeså¤´éƒ¨: {:?}", accept_ranges);
        } else {
            info!("   Accept-Rangeså¤´éƒ¨: æœªæä¾›");
        }

        Ok((supports_range, total_size))
    }

    /// è·å–ä¸‹è½½å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„ â­
    fn get_metadata_path(&self, download_path: &Path) -> std::path::PathBuf {
        download_path.with_extension("download")
    }

    /// ä¿å­˜ä¸‹è½½å…ƒæ•°æ® â­
    async fn save_metadata(&self, download_path: &Path, metadata: &DownloadMetadata) -> Result<()> {
        self.save_metadata_with_logging(download_path, metadata, true)
            .await
    }

    /// ä¿å­˜ä¸‹è½½å…ƒæ•°æ®ï¼ˆå¯æ§åˆ¶æ—¥å¿—è¾“å‡ºï¼‰â­
    async fn save_metadata_with_logging(
        &self,
        download_path: &Path,
        metadata: &DownloadMetadata,
        show_log: bool,
    ) -> Result<()> {
        if !self.config.enable_metadata {
            return Ok(());
        }

        let metadata_path = self.get_metadata_path(download_path);
        let json_content = serde_json::to_string_pretty(metadata)
            .map_err(|e| DuckError::custom(format!("åºåˆ—åŒ–å…ƒæ•°æ®å¤±è´¥: {e}")))?;

        tokio::fs::write(&metadata_path, json_content)
            .await
            .map_err(|e| DuckError::custom(format!("ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")))?;

        if show_log {
            info!("ğŸ’¾ å·²ä¿å­˜ä¸‹è½½å…ƒæ•°æ®: {}", metadata_path.display());
        }
        Ok(())
    }

    /// åŠ è½½ä¸‹è½½å…ƒæ•°æ® â­
    async fn load_metadata(&self, download_path: &Path) -> Result<Option<DownloadMetadata>> {
        if !self.config.enable_metadata {
            return Ok(None);
        }

        let metadata_path = self.get_metadata_path(download_path);
        if !metadata_path.exists() {
            return Ok(None);
        }

        let content = tokio::fs::read_to_string(&metadata_path)
            .await
            .map_err(|e| DuckError::custom(format!("è¯»å–å…ƒæ•°æ®å¤±è´¥: {e}")))?;

        let metadata: DownloadMetadata = serde_json::from_str(&content)
            .map_err(|e| DuckError::custom(format!("è§£æå…ƒæ•°æ®å¤±è´¥: {e}")))?;

        info!("ğŸ“‹ å·²åŠ è½½ä¸‹è½½å…ƒæ•°æ®: {}", metadata_path.display());
        Ok(Some(metadata))
    }

    /// æ¸…ç†ä¸‹è½½å…ƒæ•°æ® â­
    async fn cleanup_metadata(&self, download_path: &Path) -> Result<()> {
        if !self.config.enable_metadata {
            return Ok(());
        }

        let metadata_path = self.get_metadata_path(download_path);
        if metadata_path.exists() {
            tokio::fs::remove_file(&metadata_path)
                .await
                .map_err(|e| DuckError::custom(format!("æ¸…ç†å…ƒæ•°æ®å¤±è´¥: {e}")))?;
            info!("ğŸ§¹ å·²æ¸…ç†ä¸‹è½½å…ƒæ•°æ®: {}", metadata_path.display());
        }
        Ok(())
    }

    /// æ™ºèƒ½æ£€æŸ¥æ–­ç‚¹ç»­ä¼ å¯è¡Œæ€§ â­
    async fn check_resume_feasibility(
        &self,
        download_path: &Path,
        total_size: u64,
        expected_hash: Option<&str>,
    ) -> Result<Option<u64>> {
        info!("ğŸ” æ£€æŸ¥æ–­ç‚¹ç»­ä¼ å¯è¡Œæ€§...");

        // 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if !download_path.exists() {
            info!("ğŸ“ ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•ç»­ä¼ ");
            return Ok(None);
        }

        // 2. è·å–å½“å‰æ–‡ä»¶å¤§å°
        let file_metadata = tokio::fs::metadata(download_path)
            .await
            .map_err(|e| DuckError::custom(format!("è¯»å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: {e}")))?;
        let existing_size = file_metadata.len();

        info!(
            "ğŸ“Š å½“å‰æ–‡ä»¶å¤§å°: {} bytes ({:.2} MB)",
            existing_size,
            existing_size as f64 / 1024.0 / 1024.0
        );

        // 3. ã€ä¼˜å…ˆã€‘æ£€æŸ¥hashæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™ä¼˜å…ˆéªŒè¯hash â­
        if let Some(expected_hash) = expected_hash {
            info!("ğŸ” ä¼˜å…ˆè¿›è¡ŒhashéªŒè¯...");
            match Self::calculate_file_hash(download_path).await {
                Ok(actual_hash) => {
                    if actual_hash.to_lowercase() == expected_hash.to_lowercase() {
                        info!("âœ… æ–‡ä»¶hashéªŒè¯é€šè¿‡ï¼Œæ–‡ä»¶å·²å®Œæ•´");
                        // æ¸…ç†å…ƒæ•°æ®ï¼ˆä¸‹è½½å·²å®Œæˆï¼‰
                        let _ = self.cleanup_metadata(download_path).await;
                        return Ok(None); // æ— éœ€ä¸‹è½½
                    } else {
                        info!("âŒ æ–‡ä»¶hashéªŒè¯å¤±è´¥ï¼Œè¿›å…¥æ–­ç‚¹ç»­ä¼ åˆ¤æ–­");
                        info!("   æœŸæœ›hash: {}", expected_hash);
                        info!("   å®é™…hash: {}", actual_hash);
                        // ç»§ç»­ä¸‹é¢çš„æ–­ç‚¹ç»­ä¼ é€»è¾‘ï¼Œä¸è¦ç«‹å³åˆ é™¤æ–‡ä»¶
                    }
                }
                Err(e) => {
                    warn!("âš ï¸ è®¡ç®—æ–‡ä»¶hashå¤±è´¥: {}ï¼Œè¿›å…¥æ–­ç‚¹ç»­ä¼ åˆ¤æ–­", e);
                    // ç»§ç»­ä¸‹é¢çš„æ–­ç‚¹ç»­ä¼ é€»è¾‘
                }
            }
        }

        // 4. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å®Œæ•´ï¼ˆå¤§å°æ£€æŸ¥ï¼‰
        if existing_size >= total_size {
            // å¦‚æœæ–‡ä»¶å¤§å°å·²å®Œæ•´ä½†hashä¸åŒ¹é…ï¼Œè¯´æ˜æ–‡ä»¶æŸåï¼Œé‡æ–°ä¸‹è½½
            if expected_hash.is_some() {
                warn!("âŒ æ–‡ä»¶å¤§å°å®Œæ•´ä½†hashä¸åŒ¹é…ï¼Œæ–‡ä»¶å·²æŸåï¼Œå°†é‡æ–°ä¸‹è½½");
                let _ = tokio::fs::remove_file(download_path).await;
                let _ = self.cleanup_metadata(download_path).await;
                return Ok(None); // é‡æ–°ä¸‹è½½
            } else {
                // æ²¡æœ‰hashéªŒè¯ï¼Œè®¤ä¸ºæ–‡ä»¶å®Œæ•´
                info!("âœ… æ–‡ä»¶å¤§å°å®Œæ•´ä¸”æ— hashéªŒè¯è¦æ±‚ï¼Œè®¤ä¸ºæ–‡ä»¶å®Œæ•´");
                let _ = self.cleanup_metadata(download_path).await;
                return Ok(None);
            }
        }

        // 5. æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ç¬¦åˆç»­ä¼ é˜ˆå€¼
        if existing_size < self.config.resume_threshold {
            info!(
                "ğŸ“ æ–‡ä»¶è¿‡å° ({} bytes < {} bytes)ï¼Œå°†é‡æ–°ä¸‹è½½",
                existing_size, self.config.resume_threshold
            );
            let _ = tokio::fs::remove_file(download_path).await;
            let _ = self.cleanup_metadata(download_path).await;
            return Ok(None);
        }

        Ok(Some(existing_size))
    }

    /// ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰â­
    pub async fn download_file<F>(
        &self,
        url: &str,
        download_path: &Path,
        progress_callback: Option<F>,
    ) -> Result<()>
    where
        F: Fn(DownloadProgress) + Send + Sync + 'static,
    {
        self.download_file_with_options(url, download_path, progress_callback, None, None)
            .await
    }

    /// ä¸‹è½½æ–‡ä»¶ï¼ˆå¸¦é¢å¤–é€‰é¡¹ï¼‰â­
    pub async fn download_file_with_options<F>(
        &self,
        url: &str,
        download_path: &Path,
        progress_callback: Option<F>,
        expected_hash: Option<&str>,
        version: Option<&str>,
    ) -> Result<()>
    where
        F: Fn(DownloadProgress) + Send + Sync + 'static,
    {
        let downloader_type = self.get_downloader_type(url);
        let version = version.unwrap_or("unknown");

        info!("ğŸŒ å¼€å§‹ä¸‹è½½æ–‡ä»¶");
        info!("   URL: {}", url);
        info!("   ç›®æ ‡è·¯å¾„: {}", download_path.display());
        info!("   ä¸‹è½½å™¨ç±»å‹: {:?}", downloader_type);
        info!(
            "   æ–­ç‚¹ç»­ä¼ : {}",
            if self.config.enable_resume {
                "å¯ç”¨"
            } else {
                "ç¦ç”¨"
            }
        );
        if let Some(hash) = expected_hash {
            info!("   æœŸæœ›Hash: {}", hash);
        }
        info!("   ç‰ˆæœ¬æ ‡è¯†: {}", version);

        // æ£€æŸ¥Rangeæ”¯æŒå’Œæ–‡ä»¶å¤§å°
        let (supports_range, total_size) = self.check_range_support(url).await?;

        if total_size > 0 {
            info!(
                "ğŸ“¦ æœåŠ¡å™¨æ–‡ä»¶å¤§å°: {} bytes ({:.2} MB)",
                total_size,
                total_size as f64 / 1024.0 / 1024.0
            );
        }

        if supports_range && self.config.enable_resume {
            info!("âœ… æœåŠ¡å™¨æ”¯æŒRangeè¯·æ±‚ï¼Œå¯ç”¨æ–­ç‚¹ç»­ä¼ ");
        } else if !supports_range {
            warn!("âš ï¸ æœåŠ¡å™¨ä¸æ”¯æŒRangeè¯·æ±‚ï¼Œä½¿ç”¨æ™®é€šä¸‹è½½");
        }

        // æ™ºèƒ½æ£€æŸ¥æ–­ç‚¹ç»­ä¼ å¯è¡Œæ€§
        let existing_size = if supports_range && self.config.enable_resume {
            self.check_resume_feasibility(download_path, total_size, expected_hash)
                .await?
        } else {
            None
        };

        // åˆ›å»ºä¸‹è½½å…ƒæ•°æ®
        let mut metadata = DownloadMetadata::new(
            url.to_string(),
            total_size,
            expected_hash.map(|s| s.to_string()),
            version.to_string(),
        );

        // å¦‚æœæ˜¯ç»­ä¼ ï¼Œæ›´æ–°è¿›åº¦
        if let Some(resume_size) = existing_size {
            metadata.update_progress(resume_size);
        }

        // ä¿å­˜åˆå§‹å…ƒæ•°æ®
        self.save_metadata(download_path, &metadata).await?;

        // æ‰§è¡Œä¸‹è½½
        let result = match downloader_type {
            DownloaderType::Http => {
                self.download_via_http_with_resume(
                    url,
                    download_path,
                    progress_callback,
                    existing_size,
                    total_size,
                    &mut metadata,
                )
                .await
            }
            DownloaderType::HttpExtendedTimeout => {
                self.download_via_http_extended_timeout_with_resume(
                    url,
                    download_path,
                    progress_callback,
                    existing_size,
                    total_size,
                    &mut metadata,
                )
                .await
            }
        };

        // å¤„ç†ä¸‹è½½ç»“æœ
        match result {
            Ok(_) => {
                // ä¸‹è½½æˆåŠŸï¼Œæ¸…ç†å…ƒæ•°æ®
                info!("ğŸ‰ ä¸‹è½½å®Œæˆï¼Œæ¸…ç†å…ƒæ•°æ®");
                let _ = self.cleanup_metadata(download_path).await;

                // æœ€ç»ˆhashéªŒè¯ï¼ˆå¦‚æœæä¾›ï¼‰
                if let Some(hash) = expected_hash {
                    info!("ğŸ” æœ€ç»ˆhashéªŒè¯...");
                    match Self::calculate_file_hash(download_path).await {
                        Ok(actual_hash) => {
                            if actual_hash.to_lowercase() == hash.to_lowercase() {
                                info!("âœ… æœ€ç»ˆhashéªŒè¯é€šè¿‡");
                            } else {
                                warn!("âŒ æœ€ç»ˆhashéªŒè¯å¤±è´¥");
                                warn!("   æœŸæœ›: {}", hash);
                                warn!("   å®é™…: {}", actual_hash);
                                return Err(anyhow::anyhow!("æ–‡ä»¶hashéªŒè¯å¤±è´¥"));
                            }
                        }
                        Err(e) => {
                            warn!("âš ï¸ è®¡ç®—æœ€ç»ˆhashå¤±è´¥: {}", e);
                        }
                    }
                }
                Ok(())
            }
            Err(e) => {
                // ä¸‹è½½å¤±è´¥ï¼Œä¿ç•™å…ƒæ•°æ®ç”¨äºä¸‹æ¬¡ç»­ä¼ 
                warn!("âŒ ä¸‹è½½å¤±è´¥: {}", e);
                info!("ğŸ’¾ ä¿ç•™å…ƒæ•°æ®ç”¨äºä¸‹æ¬¡ç»­ä¼ ");
                Err(e)
            }
        }
    }

    /// ä½¿ç”¨æ™®é€š HTTP ä¸‹è½½ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰â­
    async fn download_via_http_with_resume<F>(
        &self,
        url: &str,
        download_path: &Path,
        progress_callback: Option<F>,
        existing_size: Option<u64>,
        total_size: u64,
        metadata: &mut DownloadMetadata,
    ) -> Result<()>
    where
        F: Fn(DownloadProgress) + Send + Sync + 'static,
    {
        info!("ğŸ“¥ ä½¿ç”¨æ™®é€š HTTP ä¸‹è½½");
        self.download_with_resume_internal(
            url,
            download_path,
            progress_callback,
            existing_size,
            total_size,
            "http_download",
            metadata,
        )
        .await
    }

    /// ä½¿ç”¨æ‰©å±•è¶…æ—¶çš„ HTTP ä¸‹è½½ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰â­
    async fn download_via_http_extended_timeout_with_resume<F>(
        &self,
        url: &str,
        download_path: &Path,
        progress_callback: Option<F>,
        existing_size: Option<u64>,
        total_size: u64,
        metadata: &mut DownloadMetadata,
    ) -> Result<()>
    where
        F: Fn(DownloadProgress) + Send + Sync + 'static,
    {
        if self.is_object_storage_or_cdn_url(url) {
            info!("ğŸ“¥ ä½¿ç”¨æ‰©å±•è¶…æ—¶ HTTP ä¸‹è½½ (å¯¹è±¡å­˜å‚¨/CDN å…¬ç½‘æ–‡ä»¶)");
            info!("   ğŸ’¡ æ£€æµ‹åˆ°å…¬ç½‘è®¿é—®çš„å¯¹è±¡å­˜å‚¨/CDNæ–‡ä»¶ï¼Œæ— éœ€å¯†é’¥");
            if existing_size.is_some() {
                info!("   ğŸ”„ æ”¯æŒæ–­ç‚¹ç»­ä¼ ");
            }
        } else {
            info!("ğŸ“¥ ä½¿ç”¨æ‰©å±•è¶…æ—¶ HTTP ä¸‹è½½");
        }

        self.download_with_resume_internal(
            url,
            download_path,
            progress_callback,
            existing_size,
            total_size,
            "extended_http_download",
            metadata,
        )
        .await
    }

    /// å†…éƒ¨æ–­ç‚¹ç»­ä¼ ä¸‹è½½å®ç° â­
    async fn download_with_resume_internal<F>(
        &self,
        url: &str,
        download_path: &Path,
        progress_callback: Option<F>,
        existing_size: Option<u64>,
        total_size: u64,
        task_id: &str,
        metadata: &mut DownloadMetadata,
    ) -> Result<()>
    where
        F: Fn(DownloadProgress) + Send + Sync + 'static,
    {
        let start_byte = existing_size.unwrap_or(0);
        let is_resume = existing_size.is_some();

        // æ„å»ºè¯·æ±‚
        let mut request = self.get_http_client().get(url);

        if is_resume {
            info!("ğŸ”„ æ–­ç‚¹ç»­ä¼ ï¼šä»å­—èŠ‚ {} å¼€å§‹ä¸‹è½½", start_byte);
            request = request.header("Range", format!("bytes={start_byte}-"));
        }

        let response = request
            .send()
            .await
            .map_err(|e| DuckError::custom(format!("å‘èµ·ä¸‹è½½è¯·æ±‚å¤±è´¥: {e}")))?;

        // æ£€æŸ¥å“åº”çŠ¶æ€
        let expected_status = if is_resume { 206 } else { 200 };

        // ğŸ†• æ–­ç‚¹ç»­ä¼ å¤±è´¥è‡ªåŠ¨å›é€€æœºåˆ¶ â­
        if is_resume && response.status().as_u16() != 206 {
            warn!(
                "âš ï¸ æ–­ç‚¹ç»­ä¼ è¯·æ±‚å¤±è´¥: HTTP {} (æœŸæœ›: 206)",
                response.status()
            );

            // æ£€æŸ¥æ˜¯å¦æ˜¯æœåŠ¡å™¨ä¸æ”¯æŒRangeçš„é”™è¯¯
            if response.status().as_u16() == 200 || response.status().as_u16() == 416 {
                warn!("ğŸ”„ æœåŠ¡å™¨å¯èƒ½ä¸æ”¯æŒRangeè¯·æ±‚ï¼Œè‡ªåŠ¨å›é€€åˆ°å®Œæ•´ä¸‹è½½");

                // åˆ é™¤å·²æœ‰æ–‡ä»¶ï¼Œé‡æ–°å¼€å§‹ä¸‹è½½
                if download_path.exists() {
                    info!("ğŸ—‘ï¸ åˆ é™¤éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶ï¼Œå‡†å¤‡é‡æ–°ä¸‹è½½");
                    tokio::fs::remove_file(download_path)
                        .await
                        .map_err(|e| anyhow::anyhow!("åˆ é™¤éƒ¨åˆ†æ–‡ä»¶å¤±è´¥: {e}"))?;
                }

                // æ¸…ç†å…ƒæ•°æ®
                let _ = self.cleanup_metadata(download_path).await;

                // é‡æ–°å‘èµ·ä¸å¸¦Rangeå¤´çš„è¯·æ±‚
                info!("ğŸ“¥ é‡æ–°å‘èµ·å®Œæ•´ä¸‹è½½è¯·æ±‚");
                let new_response = self
                    .get_http_client()
                    .get(url)
                    .send()
                    .await
                    .map_err(|e| anyhow::anyhow!("å‘èµ·é‡æ–°ä¸‹è½½è¯·æ±‚å¤±è´¥: {e}"))?;

                if !new_response.status().is_success() {
                    return Err(anyhow::anyhow!(
                        "é‡æ–°ä¸‹è½½å¤±è´¥: HTTP {}",
                        new_response.status()
                    ));
                }

                // åˆ›å»ºæ–°æ–‡ä»¶å¹¶ä»å¤´å¼€å§‹ä¸‹è½½
                let mut file = File::create(download_path)
                    .await
                    .map_err(|e| anyhow::anyhow!("åˆ›å»ºæ–‡ä»¶å¤±è´¥: {e}"))?;

                // é‡ç½®å…ƒæ•°æ®
                metadata.downloaded_bytes = 0;
                metadata.start_time = chrono::Utc::now().to_rfc3339();

                return self
                    .download_stream_with_resume(
                        new_response,
                        &mut file,
                        download_path,
                        progress_callback,
                        task_id,
                        0, // ä»å¤´å¼€å§‹
                        total_size,
                        false, // ä¸æ˜¯ç»­ä¼ 
                        metadata,
                    )
                    .await;
            } else {
                return Err(anyhow::anyhow!(
                    "ä¸‹è½½å¤±è´¥: HTTP {} (æœŸæœ›: {})",
                    response.status(),
                    expected_status,
                ));
            }
        } else if response.status().as_u16() != expected_status {
            return Err(anyhow::anyhow!(
                "ä¸‹è½½å¤±è´¥: HTTP {} (æœŸæœ›: {})",
                response.status(),
                expected_status,
            ));
        }

        // æ‰“å¼€æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼æˆ–åˆ›å»ºæ¨¡å¼ï¼‰
        let mut file = if is_resume {
            info!("ğŸ“ ä»¥è¿½åŠ æ¨¡å¼æ‰“å¼€æ–‡ä»¶");
            OpenOptions::new()
                .create(true)
                .append(true)
                .open(download_path)
                .await
                .map_err(|e| DuckError::custom(format!("æ‰“å¼€æ–‡ä»¶å¤±è´¥: {e}")))?
        } else {
            info!("ğŸ“ åˆ›å»ºæ–°æ–‡ä»¶");
            File::create(download_path)
                .await
                .map_err(|e| DuckError::custom(format!("åˆ›å»ºæ–‡ä»¶å¤±è´¥: {e}")))?
        };

        // æ‰§è¡Œä¸‹è½½
        self.download_stream_with_resume(
            response,
            &mut file,
            download_path,
            progress_callback,
            task_id,
            start_byte,
            total_size,
            is_resume,
            metadata,
        )
        .await
    }

    /// é€šç”¨çš„æµå¼ä¸‹è½½å¤„ç†ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰â­
    async fn download_stream_with_resume<F>(
        &self,
        response: reqwest::Response,
        file: &mut File,
        download_path: &Path,
        progress_callback: Option<F>,
        task_id: &str,
        start_byte: u64,
        total_size: u64,
        is_resume: bool,
        metadata: &mut DownloadMetadata,
    ) -> Result<()>
    where
        F: Fn(DownloadProgress) + Send + Sync + 'static,
    {
        let mut downloaded = start_byte; // ä»å·²ä¸‹è½½çš„å­—èŠ‚å¼€å§‹è®¡ç®—
        let mut stream = response.bytes_stream();
        let mut last_progress_time = std::time::Instant::now();
        let mut last_progress_bytes = downloaded;
        let progress_interval =
            std::time::Duration::from_secs(self.config.progress_interval_seconds);

        // é¦–æ¬¡è¿›åº¦å›è°ƒ
        if let Some(callback) = progress_callback.as_ref() {
            let status = if is_resume {
                DownloadStatus::Resuming
            } else {
                DownloadStatus::Starting
            };
            callback(DownloadProgress {
                task_id: task_id.to_string(),
                file_name: download_path
                    .file_name()
                    .unwrap_or_default()
                    .to_string_lossy()
                    .to_string(),
                downloaded_bytes: downloaded,
                total_bytes: total_size,
                download_speed: 0.0,
                eta_seconds: 0,
                percentage: if total_size > 0 {
                    downloaded as f64 / total_size as f64 * 100.0
                } else {
                    0.0
                },
                status,
            });
        }

        while let Some(chunk) = stream.next().await {
            let chunk = chunk.map_err(|e| DuckError::custom(format!("ä¸‹è½½æ•°æ®å¤±è´¥: {e}")))?;

            file.write_all(&chunk)
                .await
                .map_err(|e| DuckError::custom(format!("å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")))?;

            downloaded += chunk.len() as u64;

            // è°ƒç”¨è¿›åº¦å›è°ƒ
            if let Some(callback) = progress_callback.as_ref() {
                let progress = if total_size > 0 {
                    downloaded as f64 / total_size as f64 * 100.0
                } else {
                    0.0
                };

                callback(DownloadProgress {
                    task_id: task_id.to_string(),
                    file_name: download_path
                        .file_name()
                        .unwrap_or_default()
                        .to_string_lossy()
                        .to_string(),
                    downloaded_bytes: downloaded,
                    total_bytes: total_size,
                    download_speed: 0.0,
                    eta_seconds: 0,
                    percentage: progress,
                    status: DownloadStatus::Downloading,
                });
            }

            // è¿›åº¦æ˜¾ç¤ºé€»è¾‘
            if self.config.enable_progress_logging {
                let now = std::time::Instant::now();
                let bytes_since_last = downloaded - last_progress_bytes;
                let time_since_last = now.duration_since(last_progress_time);

                let should_show_progress = bytes_since_last >= self.config.progress_bytes_interval ||  // æ ¹æ®é…ç½®çš„å­—èŠ‚é—´éš”æ˜¾ç¤º
                    time_since_last >= progress_interval ||  // æ ¹æ®é…ç½®çš„æ—¶é—´é—´éš”æ˜¾ç¤º
                    (total_size > 0 && downloaded >= total_size); // ä¸‹è½½å®Œæˆæ—¶æ˜¾ç¤º

                if should_show_progress {
                    if total_size > 0 {
                        let percentage = (downloaded as f64 / total_size as f64 * 100.0) as u32;
                        let status_icon =
                            if is_resume && downloaded <= start_byte + 50 * 1024 * 1024 {
                                "ğŸ”„" // æ–­ç‚¹ç»­ä¼ å›¾æ ‡
                            } else {
                                "ğŸ“¥" // æ™®é€šä¸‹è½½å›¾æ ‡
                            };

                        // è®¡ç®—ä¸‹è½½é€Ÿåº¦ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼‰
                        let speed_mbps = if time_since_last.as_secs() > 0 {
                            (bytes_since_last as f64 / 1024.0 / 1024.0)
                                / time_since_last.as_secs() as f64
                        } else {
                            0.0
                        };

                        info!(
                            "{} ä¸‹è½½è¿›åº¦: {}% ({:.1}/{:.1} MB) é€Ÿåº¦: {:.1} MB/s",
                            status_icon,
                            percentage,
                            downloaded as f64 / 1024.0 / 1024.0,
                            total_size as f64 / 1024.0 / 1024.0,
                            speed_mbps
                        );
                    } else {
                        info!("ğŸ“¥ å·²ä¸‹è½½: {:.1} MB", downloaded as f64 / 1024.0 / 1024.0);
                    }

                    last_progress_time = now;
                    last_progress_bytes = downloaded;

                    // æ›´æ–°å…ƒæ•°æ®ï¼ˆå‡å°‘ä¿å­˜é¢‘ç‡ï¼Œé¿å…é‡å¤æ—¥å¿—ï¼‰â­
                    if self.config.enable_metadata {
                        metadata.update_progress(downloaded);
                        // åªåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ä¿å­˜å…ƒæ•°æ®ï¼šæ¯500MBæˆ–æ¯5åˆ†é’Ÿ
                        let should_save_metadata = bytes_since_last >= 500 * 1024 * 1024 ||  // æ¯500MBä¿å­˜ä¸€æ¬¡
                            time_since_last >= std::time::Duration::from_secs(300); // æ¯5åˆ†é’Ÿä¿å­˜ä¸€æ¬¡

                        if should_save_metadata {
                            // é™é»˜ä¿å­˜ï¼Œä¸è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…é‡å¤æ—¥å¿—ï¼‰
                            let _ = self
                                .save_metadata_with_logging(download_path, metadata, false)
                                .await;
                        }
                    }
                }
            }
        }

        // ç¡®ä¿æ–‡ä»¶å·²åˆ·æ–°åˆ°ç£ç›˜
        file.flush()
            .await
            .map_err(|e| DuckError::custom(format!("åˆ·æ–°æ–‡ä»¶ç¼“å†²åŒºå¤±è´¥: {e}")))?;

        let download_type = if is_resume {
            "æ–­ç‚¹ç»­ä¼ ä¸‹è½½"
        } else {
            "ä¸‹è½½"
        };
        info!("âœ… {}å®Œæˆ", download_type);
        info!("   æ–‡ä»¶è·¯å¾„: {}", download_path.display());
        info!(
            "   æœ€ç»ˆå¤§å°: {} bytes ({:.2} MB)",
            downloaded,
            downloaded as f64 / 1024.0 / 1024.0
        );
        if is_resume {
            info!(
                "   ç»­ä¼ å¤§å°: {} bytes ({:.2} MB)",
                downloaded - start_byte,
                (downloaded - start_byte) as f64 / 1024.0 / 1024.0
            );
        }

        Ok(())
    }

    /// è®¡ç®—æ–‡ä»¶çš„SHA256å“ˆå¸Œå€¼
    pub async fn calculate_file_hash(file_path: &Path) -> Result<String> {
        if !file_path.exists() {
            return Err(anyhow::anyhow!("æ–‡ä»¶ä¸å­˜åœ¨: {}", file_path.display()));
        }

        let mut file = File::open(file_path)
            .await
            .map_err(|e| anyhow::anyhow!("æ— æ³•æ‰“å¼€æ–‡ä»¶ {}: {}", file_path.display(), e))?;

        let mut hasher = Sha256::new();
        let mut buffer = vec![0u8; 8192]; // 8KB buffer

        loop {
            let bytes_read = file
                .read(&mut buffer)
                .await
                .map_err(|e| anyhow::anyhow!("è¯»å–æ–‡ä»¶å¤±è´¥ {}: {}", file_path.display(), e))?;

            if bytes_read == 0 {
                break;
            }

            hasher.update(&buffer[..bytes_read]);
        }

        let hash = hasher.finalize();
        Ok(format!("{hash:x}"))
    }

    /// éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    pub async fn verify_file_integrity(file_path: &Path, expected_hash: &str) -> Result<bool> {
        info!("éªŒè¯æ–‡ä»¶å®Œæ•´æ€§: {}", file_path.display());

        // è®¡ç®—å½“å‰æ–‡ä»¶çš„å“ˆå¸Œå€¼
        let actual_hash = Self::calculate_file_hash(file_path).await?;

        // æ¯”è¾ƒå“ˆå¸Œå€¼ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
        let matches = actual_hash.to_lowercase() == expected_hash.to_lowercase();

        if matches {
            info!("âœ… æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡: {}", file_path.display());
        } else {
            warn!("âŒ æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥: {}", file_path.display());
            warn!("   æœŸæœ›å“ˆå¸Œ: {}", expected_hash);
            warn!("   å®é™…å“ˆå¸Œ: {}", actual_hash);
        }

        Ok(matches)
    }
}

/// ç®€åŒ–çš„ä¸‹è½½åŠŸèƒ½ï¼Œç”¨äºå‘åå…¼å®¹
pub async fn download_file_simple(url: &str, download_path: &Path) -> Result<()> {
    let downloader = FileDownloader::default();
    downloader
        .download_file::<fn(DownloadProgress)>(url, download_path, None)
        .await
}

/// å¸¦è¿›åº¦å›è°ƒçš„ä¸‹è½½åŠŸèƒ½
pub async fn download_file_with_progress<F>(
    url: &str,
    download_path: &Path,
    progress_callback: Option<F>,
) -> Result<()>
where
    F: Fn(DownloadProgress) + Send + Sync + 'static,
{
    let downloader = FileDownloader::default();
    downloader
        .download_file(url, download_path, progress_callback)
        .await
}

/// åˆ›å»ºè‡ªå®šä¹‰é…ç½®çš„ä¸‹è½½å™¨
pub fn create_downloader(config: DownloaderConfig) -> FileDownloader {
    FileDownloader::new(config)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_aliyun_oss_url_detection() {
        let downloader = FileDownloader::default();

        // æµ‹è¯•æ‚¨æä¾›çš„çœŸå®é˜¿é‡Œäº‘ OSS URL
        let real_oss_url = "https://nuwa-packages.oss-rg-china-mainland.aliyuncs.com/nuwax-client-releases/docker/20250705082538/docker.zip";
        assert!(
            downloader.is_aliyun_oss_url(real_oss_url),
            "åº”è¯¥è¯†åˆ«ä¸ºé˜¿é‡Œäº‘ OSS URL"
        );

        // æµ‹è¯•å…¶ä»–é˜¿é‡Œäº‘ OSS URL æ ¼å¼
        let test_cases = vec![
            ("https://bucket.oss-cn-hangzhou.aliyuncs.com/file.zip", true),
            (
                "https://my-bucket.oss-us-west-1.aliyuncs.com/path/file.tar.gz",
                true,
            ),
            (
                "https://test.oss-ap-southeast-1.aliyuncs.com/docker.zip",
                true,
            ),
            ("https://example.com/file.zip", false),
            (
                "https://github.com/user/repo/releases/download/v1.0.0/file.zip",
                false,
            ),
            ("ftp://bucket.oss-cn-beijing.aliyuncs.com/file.zip", false),
        ];

        for (url, expected) in test_cases {
            assert_eq!(
                downloader.is_aliyun_oss_url(url),
                expected,
                "URL: {url} åº”è¯¥è¿”å› {expected}"
            );
        }
    }

    #[test]
    fn test_downloader_type_detection() {
        let downloader = FileDownloader::default();

        // æµ‹è¯•æ‚¨çš„çœŸå® OSS URLï¼ˆå…¬ç½‘è®¿é—®ï¼‰
        let real_oss_url = "https://nuwa-packages.oss-rg-china-mainland.aliyuncs.com/nuwax-client-releases/docker/20250705082538/docker.zip";
        let downloader_type = downloader.get_downloader_type(real_oss_url);

        match downloader_type {
            DownloaderType::HttpExtendedTimeout => {
                println!("âœ… æ­£ç¡®è¯†åˆ«ä¸ºæ‰©å±•è¶…æ—¶ HTTP ä¸‹è½½ï¼ˆå…¬ç½‘è®¿é—®ï¼‰")
            }
            DownloaderType::Http => println!("âŒ é”™è¯¯è¯†åˆ«ä¸ºæ™®é€š HTTP ä¸‹è½½"),
        }

        // å¯¹äºé˜¿é‡Œäº‘ OSS æ–‡ä»¶ï¼Œåº”è¯¥ä½¿ç”¨æ‰©å±•è¶…æ—¶HTTPä¸‹è½½
        assert!(
            matches!(downloader_type, DownloaderType::HttpExtendedTimeout),
            "OSSæ–‡ä»¶åº”è¯¥ä½¿ç”¨æ‰©å±•è¶…æ—¶HTTPä¸‹è½½"
        );

        // æµ‹è¯•æ™®é€š HTTP URL
        let http_url = "https://github.com/user/repo/releases/download/v1.0.0/file.zip";
        assert!(
            matches!(
                downloader.get_downloader_type(http_url),
                DownloaderType::Http
            ),
            "æ™®é€š HTTP URL åº”è¯¥ä½¿ç”¨æ ‡å‡†ä¸‹è½½"
        );
    }

    #[test]
    fn test_calculate_file_hash() {
        // This is a placeholder test for file hash calculation
        // In a real scenario, you would test with actual file data
    }

    /// æµ‹è¯•OSS URLæ£€æµ‹å’ŒRangeæ”¯æŒæ£€æµ‹ â­
    #[tokio::test]
    async fn test_oss_url_detection_and_range_support() {
        let downloader = FileDownloader::default();

        // æµ‹è¯•ç”¨æˆ·æä¾›çš„OSS URL
        let oss_url = "https://nuwa-packages.oss-rg-china-mainland.aliyuncs.com/docker/20250712133533/docker.zip";

        // 1. æµ‹è¯•URLæ£€æµ‹
        println!("ğŸ” æµ‹è¯•URLæ£€æµ‹åŠŸèƒ½");
        let is_aliyun_oss = downloader.is_aliyun_oss_url(oss_url);
        let is_object_storage = downloader.is_object_storage_or_cdn_url(oss_url);
        let downloader_type = downloader.get_downloader_type(oss_url);

        println!("   URL: {oss_url}");
        println!("   æ˜¯å¦é˜¿é‡Œäº‘OSS: {is_aliyun_oss}");
        println!("   æ˜¯å¦å¯¹è±¡å­˜å‚¨/CDN: {is_object_storage}");
        println!("   ä¸‹è½½å™¨ç±»å‹: {downloader_type:?}");

        assert!(is_aliyun_oss, "åº”è¯¥è¯†åˆ«ä¸ºé˜¿é‡Œäº‘OSS URL");
        assert!(is_object_storage, "åº”è¯¥è¯†åˆ«ä¸ºå¯¹è±¡å­˜å‚¨URL");

        // 2. æµ‹è¯•Rangeæ”¯æŒæ£€æµ‹
        println!("\nğŸ” æµ‹è¯•Rangeæ”¯æŒæ£€æµ‹åŠŸèƒ½");
        println!("   å¼€å§‹HEADè¯·æ±‚æ£€æµ‹...");

        // ğŸ†• æ‰‹åŠ¨æ‰§è¡ŒHEADè¯·æ±‚è¿›è¡Œè°ƒè¯• â­
        let client = downloader.get_http_client();
        println!("   åˆ›å»ºHTTPå®¢æˆ·ç«¯å®Œæˆ");

        match client.head(oss_url).send().await {
            Ok(response) => {
                println!("   HTTPå“åº”çŠ¶æ€: {}", response.status());
                println!("   å“åº”å¤´éƒ¨è¯¦æƒ…:");
                for (name, value) in response.headers().iter() {
                    if let Ok(value_str) = value.to_str() {
                        println!("     {name}: {value_str}");
                    } else {
                        println!("     {name}: <non-UTF8 value>");
                    }
                }

                let content_length = response.content_length();
                println!("   Content-Length (reqwestè§£æ): {content_length:?}");

                // ğŸ†• ä½¿ç”¨ä¿®å¤åçš„è§£æé€»è¾‘ â­
                let actual_size = if let Some(size) = content_length {
                    if size == 0 {
                        // æ‰‹åŠ¨è§£æContent-Lengthå¤´éƒ¨
                        if let Some(content_length_header) =
                            response.headers().get("content-length")
                        {
                            if let Ok(content_length_str) = content_length_header.to_str() {
                                if let Ok(parsed_size) = content_length_str.parse::<u64>() {
                                    println!("   æ‰‹åŠ¨è§£æContent-Length: {parsed_size} bytes");
                                    parsed_size
                                } else {
                                    println!("   Content-Lengthè§£æå¤±è´¥: {content_length_str}");
                                    0
                                }
                            } else {
                                println!("   Content-Lengthå¤´éƒ¨ä¸æ˜¯æœ‰æ•ˆçš„UTF-8");
                                0
                            }
                        } else {
                            println!("   æ²¡æœ‰Content-Lengthå¤´éƒ¨");
                            0
                        }
                    } else {
                        size
                    }
                } else {
                    println!("   reqwestæœªè¿”å›Content-Length");
                    0
                };

                println!(
                    "   æœ€ç»ˆæ–‡ä»¶å¤§å°: {} bytes ({:.2} GB)",
                    actual_size,
                    actual_size as f64 / 1024.0 / 1024.0 / 1024.0
                );
            }
            Err(e) => {
                println!("   HEADè¯·æ±‚å¤±è´¥: {e}");
                panic!("HEADè¯·æ±‚åº”è¯¥æˆåŠŸ");
            }
        }

        // 3. ä½¿ç”¨åŸå§‹çš„check_range_supportæ–¹æ³•
        println!("\nğŸ” ä½¿ç”¨åŸå§‹çš„check_range_supportæ–¹æ³•");
        match downloader.check_range_support(oss_url).await {
            Ok((supports_range, total_size)) => {
                println!("   Rangeæ”¯æŒ: {supports_range}");
                println!(
                    "   æ–‡ä»¶å¤§å°: {} bytes ({:.2} GB)",
                    total_size,
                    total_size as f64 / 1024.0 / 1024.0 / 1024.0
                );

                assert!(supports_range, "OSSæœåŠ¡å™¨åº”è¯¥æ”¯æŒRangeè¯·æ±‚");
                if total_size == 0 {
                    println!("   âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶å¤§å°ä¸º0ï¼Œè¿™å¯èƒ½è¡¨æ˜check_range_supportæ–¹æ³•æœ‰é—®é¢˜");
                }
            }
            Err(e) => {
                println!("   æ£€æµ‹å¤±è´¥: {e}");
                panic!("Rangeæ”¯æŒæ£€æµ‹åº”è¯¥æˆåŠŸ");
            }
        }

        println!("\nâœ… æ‰€æœ‰æ£€æµ‹åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼");
    }
}
